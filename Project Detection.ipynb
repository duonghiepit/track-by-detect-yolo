{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9514cd4-44db-4e29-bfb9-46735e835342",
   "metadata": {},
   "source": [
    "# 0. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7438cd9d-4271-469b-b0ca-6641cef0c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under MOT17.zip\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://motchallenge.net/data/MOT17.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe042ed-64a2-4041-a667-50162122ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Track by Detect\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a8bca1-624f-4e07-80d2-ec387a117b0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOT17.zip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m----> 4\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('MOT17.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8a401-5cc1-47d4-906a-fe47d6070564",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0887a593-fd00-4295-9e2e-39ddec507457",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8515dee3-fe5f-4c31-af68-e11d1fe5d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\envs\\trackbydetect\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf5fd8a-776a-48c8-8f1b-0a9a0baa71bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.3 ðŸš€ Python-3.11.7 torch-2.1.2+cpu CPU (12th Gen Intel Core(TM) i5-12400F)\n",
      "Setup complete âœ… (12 CPUs, 15.8 GB RAM, 175.7/237.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f6aea-400f-48fb-af92-5d6c4451e831",
   "metadata": {},
   "source": [
    "# 2. Convert to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "943e0671-3141-4d22-a31e-d3b9c4259666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_yolo_format(bb, img_width, img_height):\n",
    "    x_center = bb['bb_left'] + (bb['bb_width'] / 2)\n",
    "    y_center = bb['bb_top'] = (bb['bb_height'] / 2)\n",
    "\n",
    "    # Normalize the coordinates by the dimensions of the image\n",
    "    x_center /= img_width\n",
    "    y_center /= img_height\n",
    "    bb_width_nomalized = bb['bb_width'] / img_width\n",
    "    bb_height_normalized = bb['bb_height'] / img_height\n",
    "\n",
    "    # Clip the values to make sure they are between 0 and 1\n",
    "    x_center = max(min(x_center, 1), 0)\n",
    "    y_center = max(min(y_center, 1), 0)\n",
    "    bb_width_nomalized = max(min(bb_width_nomalized, 1), 0)\n",
    "    bb_height_normalized = max(min(bb_height_normalized, 1), 0)\n",
    "\n",
    "    return (x_center, y_center, bb_width_nomalized, bb_height_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "144b4fd5-286e-4d76-8c4a-65ae090ec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path):\n",
    "    # Read image dimensions from seqinfo.ini\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(os.path.join(folder_path, 'seqinfo.ini'))\n",
    "    img_width = int(config['Sequence']['imWidth'])\n",
    "    img_height = int(config['Sequence']['imHeight'])\n",
    "\n",
    "    # Load ground truth data\n",
    "    gt_path = os.path.join(folder_path, 'det/det.txt')\n",
    "    gt_data = pd.read_csv(\n",
    "        gt_path,\n",
    "        header=None,\n",
    "        names=['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'conf', 'class', 'visibility']\n",
    "    )\n",
    "\n",
    "    labels_folder = os.path.join(folder_path, 'labels')\n",
    "    os.makedirs(labels_folder, exist_ok=True)\n",
    "\n",
    "    for frame_number in gt_data['frame'].unique():\n",
    "        frame_data = gt_data[gt_data['frame'] == frame_number]\n",
    "        label_file = os.path.join(labels_folder, f'{frame_number:06d}.txt')\n",
    "\n",
    "        with open(label_file, 'w') as file:\n",
    "            for _, row in frame_data.iterrows():\n",
    "                yolo_bb = convert_to_yolo_format(row, img_width, img_height)\n",
    "                file.write(f'0 {yolo_bb[0]} {yolo_bb[1]} {yolo_bb[2]} {yolo_bb[3]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7c12c91-9ac3-4032-89c5-a93f1738339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_folders(base_directory):\n",
    "    # List all subdirectories in the base directory\n",
    "    for folder_name in tqdm(os.listdir(base_directory)):\n",
    "        folder_path = os.path.join(base_directory, folder_name)\n",
    "\n",
    "        # Delete folder not contain 'FRCNN' in name\n",
    "        if 'FRCNN' not in folder_name:\n",
    "            shutil.rmtree(folder_path)\n",
    "            continue\n",
    "\n",
    "        if os.path.isdir(folder_path):\n",
    "            process_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4f69588-d6e3-493c-a572-12561a5fc3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:07<00:00,  3.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:10<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "process_all_folders(os.path.join('MOT17', 'train'))\n",
    "process_all_folders(os.path.join('MOT17', 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70774d-8647-4ec0-8b3f-78cd0a5fabb6",
   "metadata": {},
   "source": [
    "# 3. Move file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75a95b45-b4cd-4a78-bf5f-eda41ab11e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_and_move_files(src_folder, dst_folder, folder_name, file_extension):\n",
    "    for filename in os.listdir(src_folder):\n",
    "        if filename.endswith(file_extension):\n",
    "            # Include folder name in the new filename\n",
    "            new_filename = f'{folder_name}_{filename}'\n",
    "            shutil.move(os.path.join(src_folder, filename), os.path.join(dst_folder, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af21742e-3344-4ba2-b361-ad5a2f106e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_all_folders(base_directory):\n",
    "    images_dir = os.path.join(base_directory, 'images')\n",
    "    labels_dir = os.path.join(base_directory, 'labels')\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    for folder_name in tqdm(os.listdir(base_directory)):\n",
    "        if folder_name in ['images', 'labels']:   # Skip these folders\n",
    "            continue\n",
    "\n",
    "        folder_path = os.path.join(base_directory, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            rename_and_move_files(os.path.join(folder_path, 'img1'), images_dir, folder_name, '.jpg')\n",
    "            rename_and_move_files(os.path.join(folder_path, 'labels'), labels_dir, folder_name, '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06d8403e-aa67-4ea0-af0f-139f090602ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "move_files_all_folders(os.path.join('MOT17', 'train'))\n",
    "move_files_all_folders(os.path.join('MOT17', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf1cef5e-2ec4-4d32-9c84-9fe5a5a72012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_subfolders(base_directory):\n",
    "    for folder_name in os.listdir(base_directory):\n",
    "        folder_path = os.path.join(base_directory, folder_name)\n",
    "        if os.path.isdir(base_directory) and folder_name not in ['images', 'labels']:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f'Remove folder: {folder_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c743c3c9-36de-4227-9b84-1403f680d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove folder: MOT17-02-FRCNN\n",
      "Remove folder: MOT17-04-FRCNN\n",
      "Remove folder: MOT17-05-FRCNN\n",
      "Remove folder: MOT17-09-FRCNN\n",
      "Remove folder: MOT17-10-FRCNN\n",
      "Remove folder: MOT17-11-FRCNN\n",
      "Remove folder: MOT17-13-FRCNN\n",
      "Remove folder: MOT17-01-FRCNN\n",
      "Remove folder: MOT17-03-FRCNN\n",
      "Remove folder: MOT17-06-FRCNN\n",
      "Remove folder: MOT17-07-FRCNN\n",
      "Remove folder: MOT17-08-FRCNN\n",
      "Remove folder: MOT17-12-FRCNN\n",
      "Remove folder: MOT17-14-FRCNN\n"
     ]
    }
   ],
   "source": [
    "delete_subfolders(os.path.join('MOT17', 'train'))\n",
    "delete_subfolders(os.path.join('MOT17', 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aedc94-0983-4454-ac4f-3cab0cb738b8",
   "metadata": {},
   "source": [
    "# 4. Create yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cf8bc6-35bc-497d-a8b2-a0ad95bc3e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\n",
    "    'objects'\n",
    "]\n",
    "dataset_root_dir = os.path.join(\n",
    "    os.getcwd(),\n",
    "    'MOT17'\n",
    ")\n",
    "yolo_yaml_path = os.path.join(\n",
    "    dataset_root_dir,\n",
    "    'mot17_data.yml'\n",
    ")\n",
    "\n",
    "data_yaml = {\n",
    "    'path': dataset_root_dir,\n",
    "    'train': 'train/images',\n",
    "    'val': 'test/images',\n",
    "    'nc': len(class_labels),\n",
    "    'names': class_labels\n",
    "}\n",
    "\n",
    "with open(yolo_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70729af3-2b0f-42fa-b44b-c30b546653cc",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de64069-e753-4ac7-a2dd-98ae9afae2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.3 ðŸš€ Python-3.11.7 torch-2.1.2+cpu CPU (12th Gen Intel Core(TM) i5-12400F)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=C:\\Users\\Admin\\Track by Detect\\MOT17\\mot17_data.yml, epochs=10, time=None, patience=50, batch=-1, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=models/yolo, name=yolov8s_mot17_det, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=models\\yolo\\yolov8s_mot17_det\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA not detected, using default CPU batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Admin\\Track by Detect\\MOT17\\train\\labels.cache... 5316 images, 0 backgrounds, 0 corrupt: 100%|\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Admin\\Track by Detect\\MOT17\\test\\labels.cache... 5908 images, 11 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆ\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to models\\yolo\\yolov8s_mot17_det\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mmodels\\yolo\\yolov8s_mot17_det\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.701      1.467      1.236         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:15:31<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [19:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.728       0.55      0.621      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.391      1.002      1.068         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:10:56<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [18:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.805      0.617      0.708      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.275     0.8818      1.023         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:07:25<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [18:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.781      0.625      0.706      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.183     0.7932     0.9947         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:07:19<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [18:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.825      0.672      0.762      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.115     0.7317     0.9677         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:07:19<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [18:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.817      0.662      0.742      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.035      0.678     0.9432         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:10:42<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [18:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.847      0.649      0.741      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9801     0.6389     0.9248         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:20:37<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [20:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.837      0.688      0.769      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9144     0.5967     0.9067         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:16:22<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [17:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141       0.85        0.7      0.779      0.431\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.8527     0.5558     0.8907         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:04:58<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [17:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.851      0.701      0.775      0.426\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.8021     0.5268     0.8771         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 333/333 [1:04:53<00:00,\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [17:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.858      0.698       0.78      0.441\n",
      "\n",
      "10 epochs completed in 14.847 hours.\n",
      "Optimizer stripped from models\\yolo\\yolov8s_mot17_det\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from models\\yolo\\yolov8s_mot17_det\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating models\\yolo\\yolov8s_mot17_det\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.3 ðŸš€ Python-3.11.7 torch-2.1.2+cpu CPU (12th Gen Intel Core(TM) i5-12400F)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185/185 [14:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.858      0.698       0.78      0.441\n",
      "Speed: 1.9ms preprocess, 133.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mmodels\\yolo\\yolov8s_mot17_det\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8s.pt')\n",
    "\n",
    "# Config\n",
    "epochs = 10\n",
    "batch_size = -1   # Auto scale base on GPU memory\n",
    "img_size = 640\n",
    "project_name = 'models/yolo'\n",
    "name = 'yolov8s_mot17_det'\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data = yolo_yaml_path,\n",
    "    epochs = epochs,\n",
    "    batch = batch_size,\n",
    "    imgsz = img_size,\n",
    "    project = project_name,\n",
    "    name = name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4029-bf63-40ba-a6c4-ab7dd8d2a25f",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2349de-be3d-4596-b074-91c59eb8d139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.3 ðŸš€ Python-3.11.7 torch-2.1.2+cpu CPU (12th Gen Intel Core(TM) i5-12400F)\n",
      "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Admin\\Track by Detect\\MOT17\\test\\labels.cache... 5908 images, 11 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆ\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 370/370 [15:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5919     110141      0.858      0.698       0.78      0.441\n",
      "Speed: 1.4ms preprocess, 140.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mmodels\\yolo\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model_path = os.path.join(\n",
    "    project_name, name, 'weights/best.pt'\n",
    ")\n",
    "model = YOLO(model_path)\n",
    "\n",
    "metrics = model.val(\n",
    "    project = project_name,\n",
    "    name = 'detect/val'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459ddf0-5e65-422b-a17d-cb2c5ce40516",
   "metadata": {},
   "source": [
    "# 7. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7044affd-e374-4a1b-a272-c4814d3dfb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Track by Detect'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbd9fec-63b9-4ea4-b538-c924a91c81ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Admin\\Track by Detect\\MOT17-01-FRCNN_000001.jpg: 384x640 10 objectss, 152.9ms\n",
      "Speed: 13.1ms preprocess, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mmodels\\yolo\\detect\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sample_path = os.path.join(path, 'MOT17-01-FRCNN_000001.jpg')\n",
    "results = model.predict(\n",
    "    sample_path,\n",
    "    project = project_name,\n",
    "    name = 'detect/predict',\n",
    "    save = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61e47d3-0c2f-4c67-be75-949473d1b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree(os.path.join(path, 'models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41966af-1202-4ed8-8488-9435d7d59ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
